# # Install required libraries
!pip install ultralytics opencv-python torch torchvision -q

import os
import zipfile
from ultralytics import YOLO
from google.colab import files

# Define paths
dataset_zip = "/content/Scaffolding.v7-final-one.yolov8.zip"  # Path to your uploaded zip file
dataset_path = "/content/scaffolding_dataset"  # Where to extract the dataset

# Unzip the dataset
if os.path.exists(dataset_zip):
    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
        zip_ref.extractall(dataset_path)
    print(f"Extracted dataset to {dataset_path}")
else:
    raise FileNotFoundError(f"Zip file {dataset_zip} not found. Please upload it.")

# List extracted files to verify structure
print("Extracted folder contents:", os.listdir(dataset_path))

# Find data.yaml (it might be in a subdirectory)
data_yaml = None
for root, dirs, files in os.walk(dataset_path):
    if "data.yaml" in files:
        data_yaml = os.path.join(root, "data.yaml")
        break

if not data_yaml or not os.path.exists(data_yaml):
    raise FileNotFoundError(f"data.yaml not found in {dataset_path}. Check dataset structure.")

print(f"Found data.yaml at {data_yaml}")

# Update data.yaml paths if necessary (ensure absolute paths)
with open(data_yaml, 'r') as f:
    lines = f.readlines()

updated_lines = []
for line in lines:
    if line.startswith('train:'):
        updated_lines.append(f"train: {os.path.join(dataset_path, 'train/images')}\n")
    elif line.startswith('val:'):
        updated_lines.append(f"val: {os.path.join(dataset_path, 'valid/images')}\n")
    elif line.startswith('test:'):
        updated_lines.append(f"test: {os.path.join(dataset_path, 'test/images')}\n")
    else:
        updated_lines.append(line)

with open(data_yaml, 'w') as f:
    f.writelines(updated_lines)

# Load the YOLOv8 model
model = YOLO("yolov8n.pt")  # Nano model; use yolov8s.pt for better accuracy if needed

# Train the model
model.train(
    data=data_yaml,  # Path to data.yaml
    epochs=50,      # Number of training epochs
    imgsz=640,       # Image size (matches dataset preprocessing)
    batch=16,        # Batch size (reduce to 8 if GPU memory error occurs)
    name="scaffolding_yolov8",  # Training run name
    patience=10,     # Early stopping after 10 epochs of no improvement
    device=0,        # Use GPU
    optimizer="AdamW",  # Optimizer
    lr0=0.001,       # Initial learning rate
    augment=True     # Enable data augmentation
)

# Save the trained model
model.save("scaffolding_yolov8_trained.pt")

# # Download the trained model
# files.download("scaffolding_yolov8_trained.pt")

# # Download training results
# results_dir = "runs/train/scaffolding_yolov8"
# if os.path.exists(results_dir):
#     !zip -r scaffolding_yolov8_results.zip {results_dir}
#     files.download("scaffolding_yolov8_results.zip")
from ultralytics import YOLO
import os
import zipfile
import cv2
import matplotlib.pyplot as plt
from google.colab import files

# Define paths
zip_path = "/content/Scaffolding.v7-final-one.yolov8.zip"  # Path to your zip file
dataset_path = "/content/scaffolding_dataset"  # Where to extract the dataset
test_images_dir = os.path.join(dataset_path, "test/images")  # Test images path
output_dir = "/content/predictions"  # Directory to save predictions
model_path = "scaffolding_yolov8_trained.pt"  # Path to your trained model
data_yaml = os.path.join(dataset_path, "data.yaml")  # Path to data.yaml

# Unzip the dataset
if os.path.exists(zip_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(dataset_path)
    print(f"Extracted dataset to {dataset_path}")
else:
    raise FileNotFoundError(f"Zip file {zip_path} not found. Please upload it.")

# Verify data.yaml exists
if not os.path.exists(data_yaml):
    raise FileNotFoundError(f"data.yaml not found at {data_yaml}. Check dataset structure.")

# Verify test images directory exists
if not os.path.exists(test_images_dir):
    raise FileNotFoundError(f"Test images directory {test_images_dir} not found. Check dataset structure.")

# Create output directory if it doesn't exist
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Load the trained model
if not os.path.exists(model_path):
    raise FileNotFoundError(f"Model file {model_path} not found. Ensure it is in /content/.")
model = YOLO(model_path)

# Get list of test images
test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]

# Check if test images exist
if not test_images:
    raise FileNotFoundError(f"No images found in {test_images_dir}. Ensure the test/images folder contains .jpg, .jpeg, or .png files.")

# Run inference on test images
results = model.predict(
    source=test_images_dir,  # Directory containing test images
    conf=0.25,               # Confidence threshold for predictions
    iou=0.45,                # IoU threshold for non-max suppression
    save=True,               # Save annotated images
    save_txt=True,           # Save predictions in YOLO format (text files)
    save_conf=True,          # Include confidence scores in text files
    project=output_dir,      # Output directory
    name="test_predictions"  # Subdirectory for this run
)

# Visualize first 5 results
for i, result in enumerate(results[:5]):  # Show first 5 images
    # Load the annotated image
    img_path = os.path.join(result.save_dir, os.path.basename(result.path))
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib

    # Display the image
    plt.figure(figsize=(10, 10))
    plt.imshow(img)
    plt.title(f"Prediction for {os.path.basename(result.path)}")
    plt.axis('off')
    plt.show()

# Zip and download the prediction results
zip_output = "/content/predictions.zip"
os.system(f"zip -r {zip_output} {output_dir}")
files.download(zip_output)
